<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>1부 딥러닝의 기초 - 2장 시작하기 전에 : 신경망의 수학적 구성 요소 </title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-opaquegray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="13c4243a-ade0-4ad3-8568-70d7b3fc0d63" class="page sans"><header><h1 class="page-title">1부 딥러닝의 기초 - 2장 시작하기 전에 : 신경망의 수학적 구성 요소 </h1><table class="properties"><tbody><tr class="property-row property-row-date"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesDate"><path d="M10.8889,5.5 L3.11111,5.5 L3.11111,7.05556 L10.8889,7.05556 L10.8889,5.5 Z M12.4444,1.05556 L11.6667,1.05556 L11.6667,0 L10.1111,0 L10.1111,1.05556 L3.88889,1.05556 L3.88889,0 L2.33333,0 L2.33333,1.05556 L1.55556,1.05556 C0.692222,1.05556 0.00777777,1.75556 0.00777777,2.61111 L0,12.5 C0,13.3556 0.692222,14 1.55556,14 L12.4444,14 C13.3,14 14,13.3556 14,12.5 L14,2.61111 C14,1.75556 13.3,1.05556 12.4444,1.05556 Z M12.4444,12.5 L1.55556,12.5 L1.55556,3.94444 L12.4444,3.94444 L12.4444,12.5 Z M8.55556,8.61111 L3.11111,8.61111 L3.11111,10.1667 L8.55556,10.1667 L8.55556,8.61111 Z"></path></svg></span>시작일</th><td><time>@2022년 7월 18일</time></td></tr><tr class="property-row property-row-url"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesUrl"><path d="M3.73333,3.86667 L7.46667,3.86667 C8.49613,3.86667 9.33333,4.70387 9.33333,5.73333 C9.33333,6.7628 8.49613,7.6 7.46667,7.6 L6.53333,7.6 C6.01813,7.6 5.6,8.0186 5.6,8.53333 C5.6,9.04807 6.01813,9.46667 6.53333,9.46667 L7.46667,9.46667 C9.5284,9.46667 11.2,7.79507 11.2,5.73333 C11.2,3.6716 9.5284,2 7.46667,2 L3.73333,2 C1.6716,2 0,3.6716 0,5.73333 C0,7.124 0.762067,8.33453 1.88953,8.97713 C1.87553,8.83107 1.86667,8.6836 1.86667,8.53333 C1.86667,7.92013 1.98753,7.33447 2.2036,6.7978 C1.99267,6.4954 1.86667,6.12953 1.86667,5.73333 C1.86667,4.70387 2.70387,3.86667 3.73333,3.86667 Z M12.1095,5.28907 C12.1231,5.4356 12.1333,5.58307 12.1333,5.73333 C12.1333,6.34607 12.0101,6.9294 11.7931,7.46513 C12.0059,7.768 12.1333,8.13573 12.1333,8.53333 C12.1333,9.5628 11.2961,10.4 10.2667,10.4 L6.53333,10.4 C5.50387,10.4 4.66667,9.5628 4.66667,8.53333 C4.66667,7.50387 5.50387,6.66667 6.53333,6.66667 L7.46667,6.66667 C7.98187,6.66667 8.4,6.24807 8.4,5.73333 C8.4,5.2186 7.98187,4.8 7.46667,4.8 L6.53333,4.8 C4.4716,4.8 2.8,6.4716 2.8,8.53333 C2.8,10.59507 4.4716,12.2667 6.53333,12.2667 L10.2667,12.2667 C12.3284,12.2667 14,10.59507 14,8.53333 C14,7.14267 13.2375,5.93167 12.1095,5.28907 Z"></path></svg></span>링크</th><td></td></tr><tr class="property-row property-row-date"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesDate"><path d="M10.8889,5.5 L3.11111,5.5 L3.11111,7.05556 L10.8889,7.05556 L10.8889,5.5 Z M12.4444,1.05556 L11.6667,1.05556 L11.6667,0 L10.1111,0 L10.1111,1.05556 L3.88889,1.05556 L3.88889,0 L2.33333,0 L2.33333,1.05556 L1.55556,1.05556 C0.692222,1.05556 0.00777777,1.75556 0.00777777,2.61111 L0,12.5 C0,13.3556 0.692222,14 1.55556,14 L12.4444,14 C13.3,14 14,13.3556 14,12.5 L14,2.61111 C14,1.75556 13.3,1.05556 12.4444,1.05556 Z M12.4444,12.5 L1.55556,12.5 L1.55556,3.94444 L12.4444,3.94444 L12.4444,12.5 Z M8.55556,8.61111 L3.11111,8.61111 L3.11111,10.1667 L8.55556,10.1667 L8.55556,8.61111 Z"></path></svg></span>종료일</th><td></td></tr></tbody></table></header><div class="page-body"><ul id="15e57e73-68c9-4f89-be51-ba2f6b0dc4c0" class="toggle"><li><details open=""><summary>2장 시작하기 전에: 신경망의 수학적 구성 요소 </summary><p id="bdaccfa3-6c97-4bbd-af12-e6df37c32789" class="">텐서, 텐서 연산, 미분, 경사 하강법(gradient descent)등의 수학 개념과 친숙해져야 함  </p><ul id="30e55038-658e-4b1d-b39a-8a096eade38d" class="toggle"><li><details open=""><summary>2.1 신경망과의 첫 만남 </summary><ul id="9640badc-7acd-4332-8f44-994e2d6deb29" class="toggle"><li><details open=""><summary>MNIST 손글씨 숫자 분류 학습  </summary><ul id="12372f21-b2fb-47cd-9623-9bd5da7d2194" class="toggle"><li><details open=""><summary>MNIST 데이터셋 </summary><ul id="c078e2b7-cf6c-4f33-a156-29e1ec56b4e9" class="bulleted-list"><li style="list-style-type:disc">손글씨 숫자 이미지 (28 x 28 픽셀)을 10개의 범주 (0~9)까지로 분류 </li></ul><ul id="7138d431-d477-4253-9deb-a8f1af077f28" class="bulleted-list"><li style="list-style-type:disc">6만 개의 훈련 이미지, 1만 개의 텍스트 이미지 </li></ul><ul id="38f42313-ebf8-46a3-b7ad-78ca2306c79e" class="bulleted-list"><li style="list-style-type:disc">Numpy 배열 형태로 케라스에 이미 포함됨 </li></ul></details></li></ul><ul id="17f149a8-9651-42e1-a076-f3000f32cc82" class="toggle"><li><details open=""><summary>코드</summary><h2 id="52e1db79-9572-40b2-bcd2-c079859f49ab" class="">MNIST 데이터셋 </h2><ul id="ada49518-498e-486c-b736-94d088db6d9c" class="bulleted-list"><li style="list-style-type:disc">훈련 세트(training set) - train_images, train_labels </li></ul><ul id="c5f8892e-e5e9-4d26-8a05-7dbd430bfdc1" class="bulleted-list"><li style="list-style-type:disc">테스트 세트(test set) - test_images, test_labels </li></ul><pre id="9db545b8-6370-45ef-ba2c-75541b589152" class="code"><code># 케라스에서 MNIST 데이터셋 적재하기 
from keras.datasets import mnist 
(train_images,. train_labels), (test_images, test_labels) = mnist.load_data()

train_images.shape # (60,000, 28, 28)
len(train_labels) # 60,000
train_labels # array[5,0,4,,, 5,6,8], dtype = unit 8)

test_images.shape # (10,000, 28,28)
len(test_labels) # 10,000
test_labels # array[7,2,1,,,4,5,6], dtype = unit 8)</code></pre><h2 id="70eeb9c9-4391-4c1b-b39c-d63ee38f5e0c" class="">신경망 구조 </h2><ul id="b9e93a93-fb17-484d-ba7f-367beba095c0" class="bulleted-list"><li style="list-style-type:disc">데이터 처리 필터 : <code>층(layer)</code></li></ul><ul id="0750aab7-2505-4bcf-bbe0-91ebad9fc102" class="bulleted-list"><li style="list-style-type:disc">주어진 문제에 더 의미 있는 <code>표현(representation)</code>을 입력된 데이터로부터 추출 </li></ul><ul id="5de4f764-88db-4c7a-8c1d-98d05d90f39f" class="bulleted-list"><li style="list-style-type:disc"><code>완전 연결(fully connected)된 신경망 층인 Dense층</code> 2개가 연속 </li></ul><ul id="b79e2a33-1a71-4be6-802f-aad2fdd82b29" class="bulleted-list"><li style="list-style-type:disc">마지막 층은 10개의 확률 점수가 들어 있는 배열을 반환하는 <code>소프트맥스(softmax) 층 </code></li></ul><ul id="67b21c89-8ad1-45f8-844a-e826661118f2" class="bulleted-list"><li style="list-style-type:disc">각 점수는 현재 숫자 이미지가 10개의 숫자 클래스 중 하나에 속할 확률 </li></ul><pre id="7758967e-3eeb-4293-80b7-af861496fd0d" class="code"><code># 신경망 구조 
from keras import models 
from keras import layers 

network = models.Sequential()
network.add(layers.Dense(512, activation = &#x27;relu&#x27;, input_shape = (28,28,))
network.add(layers.Dense(10, activation = &#x27;softmax&#x27;)) </code></pre><h2 id="005a23f9-b9ec-4cba-91e9-ec26a489f8b6" class="">신경망 훈련 (컴파일 단계)</h2><ul id="907c5580-637e-4226-bee9-1d8ad5b52ecb" class="bulleted-list"><li style="list-style-type:disc"><code>손실 함수(loss function)</code><ul id="9abc8f95-dec7-4b5a-939e-ebf296581e4e" class="bulleted-list"><li style="list-style-type:circle">훈련 데이터, 성능 측정하는 방법 </li></ul></li></ul><ul id="3306ed0c-f3d0-426a-be0b-167ef03259f0" class="bulleted-list"><li style="list-style-type:disc"><code>옵티마이저(optimizer)</code><ul id="8b624e0c-0563-44d0-b4ba-220918083f7d" class="bulleted-list"><li style="list-style-type:circle">입력된 데이터, 손실 함수 기반으로 네트워크를 업데이터 </li></ul></li></ul><ul id="b2dd318c-cb55-430a-bac8-4fec74053031" class="bulleted-list"><li style="list-style-type:disc"><code>훈련과 테스트 과정을 모니터링할 지표 </code><ul id="66ba5cff-567e-4d9d-865e-b22255a7a84b" class="bulleted-list"><li style="list-style-type:circle">ex.여기서는 정확도(정확히 분류된 이미지의 비율)</li></ul></li></ul><pre id="aa4d0663-b0c7-4b54-9786-90043ff8f4c9" class="code"><code># 컴파일 단계 
network.compile(optimizer= &#x27;rmsprop&#x27;,
								loss= &#x27;categorical_crossentropy&#x27;, 
								metrics = [&#x27;accuracy&#x27;])</code></pre><h2 id="98cdfb80-df94-44c4-ae6d-6dbfac433173" class="">이미지 데이터 전처리 </h2><ul id="365e81b0-8c3c-4613-8515-e57be1292c4f" class="bulleted-list"><li style="list-style-type:disc">데이터를 0~1 사이로 스케일을 조정 </li></ul><ul id="a47c3f40-eef9-496d-93b6-e33238d9009c" class="bulleted-list"><li style="list-style-type:disc">[0,255] 사이의 unit8 타입의 (60,000, 28, 28) 크기를 가진 배열로 저장 </li></ul><ul id="6b821789-1ddf-4e5e-a53d-4d2d47e6a8ee" class="bulleted-list"><li style="list-style-type:disc">0과 1 사이의 값을 가지는 float32 타입의 (60,000, 28*28 크기인 배열로 바꿈)</li></ul><pre id="89297821-eaeb-4f2f-995b-04951d32c3c5" class="code"><code># 이미지 데이터 준비하기 
train_images = train_images.reshape((60000, 28*28))
train_images = train_images.astype(&#x27;float32&#x27;) / 255 

test_images = test_images.reshape(10000, 28*28))
test_images = test_images.astype(&#x27;float32&#x27;) / 255  </code></pre><pre id="deae4014-c3cb-42f5-87bc-056bdad61b69" class="code"><code># 레이블 준비하기 
from keras.utils import to_categorical 

train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)</code></pre><h2 id="904e037c-93c7-43b2-a4f4-584bbc0f66cc" class="">신경망 훈련 (fit)</h2><ul id="1388d385-3b1e-4cc7-b91f-dd2489a18951" class="bulleted-list"><li style="list-style-type:disc">fit 메서드 호출하여 훈련 데이터에 모델을 학습 </li></ul><ul id="6d07a377-51c1-448b-9534-ab2f6b90f3db" class="bulleted-list"><li style="list-style-type:disc">훈련하는 동안 2개의 정보가 출력됨 </li></ul><ul id="8d790490-1628-4258-b991-8a4ed3039f91" class="bulleted-list"><li style="list-style-type:disc">훈련 데이터에 대한 네트워크의 손실, 정확도 </li></ul><pre id="e86ba538-73c8-4dad-8540-167708432d91" class="code"><code># fit 메서드를 호출하여 훈련 데이터에 모델을 학습 
network.fit(train_images, train_labels, epoch = 5, batch_size= 128)

# 출력 예시 
# Epochs 1/5 
# 60,000/60,000 [==============] - 1s 22us/step - loss : 0.2571 - acc - 0.9257 
# Epochs 2/5 
# 60,000/60,000 [==============] - 1s 12us/step - loss : 0.1027 - acc - 0.9695 </code></pre><h2 id="f33a6760-e084-4573-bcfd-21379334bf03" class="">결과 확인 </h2><ul id="3e70c8c4-85fb-429c-b96b-e9a694f4ab10" class="bulleted-list"><li style="list-style-type:disc">test_loss, test_acc </li></ul><pre id="56b8725f-90fe-472a-9e94-3609de4dde85" class="code"><code># 테스트 세트에서도 모델이 잘 작동하는지 확인 
test_loss, test_acc = network.evaluate(test_images, test_labels) 
print(&#x27;test_acc&#x27;, test_acc)</code></pre></details></li></ul></details></li></ul><p id="3f3ab3bb-9fe9-4559-a419-00ddffd6a6f7" class="">    </p></details></li></ul><ul id="dc354ce7-3d85-451e-ba95-9bfcab7784fe" class="toggle"><li><details open=""><summary>2.2 신경망을 위한 데이터 표현</summary><ul id="539c2ed8-0175-4818-b845-8147ee40e63e" class="toggle"><li><details open=""><summary>텐서 (tensor)</summary><ul id="7ed41c4f-fb86-4d6f-9021-650f7221f2d9" class="bulleted-list"><li style="list-style-type:disc">임의의 차원 개수를 가지는 다차원 넘파이 배열  </li></ul><ul id="8b1c0e68-34fa-41ba-abe6-918f3ae6f27c" class="bulleted-list"><li style="list-style-type:disc">숫자 데이터를 위한 컨테이너(container) </li></ul><ul id="f763ebca-c048-4c61-96bb-570633091ece" class="bulleted-list"><li style="list-style-type:disc">ex. 2D 텐서: 행렬</li></ul></details></li></ul><ul id="17b67f95-06e9-4354-99bd-968bbb303b82" class="toggle"><li><details open=""><summary>2.2.1 스칼라 (0D 텐서)</summary><ul id="6a07f6eb-a2a2-458a-b1f5-220bd9b04579" class="bulleted-list"><li style="list-style-type:disc">하나의 숫자만 담고 있는 텐서를 스칼라(scala, 0차원 텐서, 0D테서)</li></ul><ul id="cf64dbcf-fc19-4750-9a70-fad4653c2c93" class="bulleted-list"><li style="list-style-type:disc">numpy 에서는 float32, float64 타입의 숫자가 스칼라 텐서</li></ul><ul id="08cd4e2d-fef2-46c0-9926-1ab4d8434f24" class="bulleted-list"><li style="list-style-type:disc">ndim: 넘파이 배열의 축 개수를 확인 </li></ul><ul id="62f359e4-3856-445c-91f3-95908706a4c6" class="bulleted-list"><li style="list-style-type:disc">스칼라 텐서의 축 개수는 0 (ndim ==0)</li></ul><ul id="eaaedda7-a47b-4e97-bd29-6010be7d6d81" class="bulleted-list"><li style="list-style-type:disc">텐서의 축 개수를 랭크(rank)라고도 부름 </li></ul><pre id="d911e4ce-38f2-4277-af2a-8638c451e8e8" class="code"><code>import numpy as np 
x = np.array(12)
x # array(12)
x.ndim # 0 </code></pre></details></li></ul><ul id="312fb332-98b3-4e3d-a728-ebc6f930458c" class="toggle"><li><details open=""><summary>2.2.2 벡터 (1D 텐서)</summary><ul id="a1442dcd-0a9e-45f3-92a8-56dcfc68feeb" class="bulleted-list"><li style="list-style-type:disc">숫자의 배열을 벡터(vector) 또는 1D 텐서라고 부름<pre id="a05d83d9-a46f-4dd5-ae45-a7b0482a4286" class="code"><code>x = np.array([12,3,6,14,7]) # 5개의 원소 - 5D 벡터 ,not 5D 텐서 
x # array([12,3,6,14,7])
x.ndim # 1 </code></pre></li></ul></details></li></ul><ul id="cf728603-e79a-4c9c-b1da-e4fd9106775b" class="toggle"><li><details open=""><summary>2.2.3 행렬 (2D 텐서)</summary><ul id="a6eabf4c-5f61-47b3-bb5a-be6b448799a1" class="bulleted-list"><li style="list-style-type:disc">벡터의 배열이 행렬(maxtrix) 또는 2D 텐서 </li></ul><ul id="ab0191ec-b3bb-4cdd-9187-f1872b7874c5" class="bulleted-list"><li style="list-style-type:disc">행렬은 2개의 축을 가짐 (행(row), 열(column)) <pre id="557495bf-0ca3-4fa7-9047-f267eb1360f4" class="code code-wrap"><code>x = np.array([5,78,2,34,0],
							[6,79,3,35,1],
							[7,89,4,36,2])

x.ndim # 2
# 첫 번째 축에 놓여 있는 원소를 행 
# 두 번째 축에 놓여 있는 원소를 열 
# x의 첫 번째 행은 [4,78,2,34,0] 
# x의 첫 번째 열을 [5,6,7] </code></pre></li></ul></details></li></ul><ul id="c9d01884-0821-4205-bfdd-55794bc1d2f4" class="toggle"><li><details open=""><summary>2.2.4 3D 텐서와 고차원 텐서</summary><ul id="c3d3bd2b-8a7d-4671-9824-bed91a3c6afb" class="bulleted-list"><li style="list-style-type:disc">행렬들을 하나의 새로운 배열로 합치면 숫자가 채워진 직육면체 형태로 해석할 수 있는 3D 텐서</li></ul><ul id="44f72c11-97aa-4448-820c-d439d024c292" class="bulleted-list"><li style="list-style-type:disc">3D 텐서를 하나의 배열로 합치면 4D ~ , 딥러닝은 보통 4D까지 다룸 </li></ul><ul id="32b535b3-d404-460c-be67-5316b4b0c506" class="bulleted-list"><li style="list-style-type:disc">동영상 데이터는 5D까지 가기도 함 <pre id="a1604a71-46a8-4c5e-a0d6-290e0ca6f23b" class="code code-wrap"><code>x = np.array([[1,2,3,4,5],
							[6,7,8,9,10],
							[11,12,13,14,15]],
						 [[1,2,3,4,5],
							[6,7,8,9,10],
							[11,12,13,14,15]],
						 [[1,2,3,4,5],
							[6,7,8,9,10],
							[11,12,13,14,15]])

x.ndim # 3 </code></pre></li></ul></details></li></ul><ul id="8346e510-249d-4e54-bfd3-96307e88c8cf" class="toggle"><li><details open=""><summary>2.2.5 핵심 속성 </summary><ul id="3fee2b21-f77c-46f8-ac92-e97df0080769" class="bulleted-list"><li style="list-style-type:disc">텐서는 3개의 속성으로 정의됨 <ul id="4cdd4304-e7a8-40e1-8442-6140c47d1c39" class="toggle"><li><details open=""><summary>축의 개수(랭크)</summary><ul id="895771cc-6851-4d99-9318-85db4bc5f528" class="bulleted-list"><li style="list-style-type:disc">3D 텐서, 3개의 축 / 행렬 , 2개의 축 </li></ul><ul id="d5888b1a-8ce0-47e7-b189-ec0bab43aacc" class="bulleted-list"><li style="list-style-type:disc">ndim 속성에 저장됨 </li></ul></details></li></ul><ul id="7e6aee97-fd72-45f7-a2b1-d9372b02a69d" class="toggle"><li><details open=""><summary>크기(shape)</summary><ul id="48797b07-4956-4ef2-9306-1e4156be750a" class="bulleted-list"><li style="list-style-type:disc">0D : 배열/스칼라 () : 크기 없음 </li></ul><ul id="665e204e-b010-41f2-8da5-2b044476e7b6" class="bulleted-list"><li style="list-style-type:disc">1D: 벡터 (5,) </li></ul><ul id="bf592caa-5404-4c54-814f-3e9d23e098fa" class="bulleted-list"><li style="list-style-type:disc">2D: 행렬의 크기 (3,5) </li></ul><ul id="366b958c-5d2e-43a3-929e-281a019fd535" class="bulleted-list"><li style="list-style-type:disc">3D: 3D 텐서의 크기 (3,3,5) </li></ul><p id="b06abf8c-a7cf-4927-9332-1cc6e77bf023" class="">
</p></details></li></ul><ul id="35eb60a2-7b2d-463e-b50d-f4e0d9a3cec2" class="toggle"><li><details open=""><summary>데이터 타입 </summary><ul id="41c5b960-76e3-4f2e-8083-8321d277a29c" class="bulleted-list"><li style="list-style-type:disc">dtype에 저장됨 </li></ul><ul id="b118c2cd-6fa6-4d34-a874-0230d9797e2e" class="bulleted-list"><li style="list-style-type:disc">텐서에 포함된 데이터의 타입 </li></ul><ul id="2b1cd1ad-dbf0-484f-a167-e6172fc0f6de" class="bulleted-list"><li style="list-style-type:disc">float32, unit8, float64 등 </li></ul><ul id="c95f5237-3469-4c1c-850f-bbcdfb43438a" class="bulleted-list"><li style="list-style-type:disc">드물게 char 타입 사용/ 가별 길이 문자열은 지원 X </li></ul></details></li></ul></li></ul><ul id="00b3defb-abe9-4f5f-a6c3-413cfa3a7729" class="bulleted-list"><li style="list-style-type:disc">MINST 속성 확인 </li></ul><pre id="e567de01-a026-4b01-bb36-885b87bee256" class="code code-wrap"><code># MNIST 데이터 불러오기 
from keras.datasets import mnist 
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# train_images 배열의 ndim 속성으로 축의 개수를 확인 
print(train_images.ndim) # 3 

# 배열의 크기 
print(train_images.shape) # (60,000, 28, 28)

# dtype, 속성 확인 
print(train_images.dtypes) # unit8 , 8비트 정슈형 3D 텐서 

# 결론 
# 28 x 28 크기의 정수 행렬 6만개 있는 배열 
# 각 행렬을 하나의 흑백 이지미 
# 행렬의 각 원소는 0~255 사이의 값을 가짐 </code></pre><pre id="a4bfce78-bd01-436b-876e-262237ce6b44" class="code code-wrap"><code># 5번째 이미지 출력 
digit = train_images[4] 

import matplotlib.pyplot as plt 
plt.imshow(digit, cmap = plt.cm.binary)
plt.show()</code></pre></details></li></ul><ul id="9ee7061f-ace4-43f3-8e45-67f79fd4a306" class="toggle"><li><details open=""><summary>2.2.6 넘파이로 텐서 조작하기  </summary><ul id="7666df0c-5aac-43a6-b28a-5ae3dc571bcf" class="bulleted-list"><li style="list-style-type:disc">train_images[i] : 첫 번째 축을 따라 특성 숫자 선택 </li></ul><ul id="c1916c7a-effd-48b9-bbc3-b1af264a2a44" class="bulleted-list"><li style="list-style-type:disc">슬라이싱(slicing)<ul id="afc1509d-30e4-4e08-95ec-efb6bf695c9d" class="bulleted-list"><li style="list-style-type:circle">배열에 있는 특정 원소를 선택 </li></ul><pre id="9bfaff17-6c9e-496c-8678-61b28258191f" class="code code-wrap"><code># 11~101번째 숫자 선택하여 (90,28,28) 크기의 배열 만듦 

# method 1 
my_slice = train_images[10:100]
print(my_slice.shape) # (90,28,28)

# method 2 
my_slice = train_images[10:100, :, :]
my_slice.shape # (90,28,28)

# method 3 
my_slice = train_images[10:100, 0:28, 0:28] 
my_slice.shape # (90,28,28)

# if, 이미지의 오른쪽 아래 14 x 14 픽셀 선택 
my_slice= train_images[:, 14:, 14:]

# 음수 인덱스 ,정중앙에 위치한 7 x 7 픽셀 
my_slice = train_images[: 7:-7, 7:-7]</code></pre></li></ul></details></li></ul><ul id="dab0da0e-290e-4e8b-b024-b9aa0dadd64b" class="toggle"><li><details open=""><summary>2.2.7 배치 데이터 </summary><ul id="94f3b794-4f2d-485b-ad1d-27a0edf06f96" class="bulleted-list"><li style="list-style-type:disc">텐서의 첫 번째 축: 샘플 축(sample axis), 샘플 차원(sample dimension)</li></ul><ul id="043a37b1-f630-46b4-bf55-be52b479b0e5" class="toggle"><li><details open=""><summary><code>배치(Batch)</code></summary><ul id="f552d146-fffc-454d-86d7-bef0417ae7f7" class="bulleted-list"><li style="list-style-type:disc">딥러닝 전체 데이터를 작음 배치(batch)로 나누어 처리 </li></ul><ul id="17f59f69-2aaf-43c0-b79b-d249bcdf0e70" class="bulleted-list"><li style="list-style-type:disc">ex. MNIST, 배치 128로 만든다면 <ul id="f7340b23-c4bd-4f79-9cf1-a3c9fb9a8747" class="bulleted-list"><li style="list-style-type:circle">1) batch = train_images[:128]</li></ul><ul id="525bc343-f46e-49ed-9275-f0b0929dba41" class="bulleted-list"><li style="list-style-type:circle">2) batch = train_images[128:256]</li></ul><ul id="48d9d278-c3f0-4199-9f65-a990ce81cbe1" class="bulleted-list"><li style="list-style-type:circle">n) batch = train_images[128*n : 128 * (n+1)]</li></ul></li></ul><ul id="cb252fe4-b469-41e4-8dbb-8e9b7fa9dfd3" class="bulleted-list"><li style="list-style-type:disc">배치 데이터 첫 번째 축 : <code>배치 축(batch axis) </code>/ <code>배치 차원(batch dimension)</code></li></ul></details></li></ul></details></li></ul><ul id="6d636476-8c69-45d6-998a-da9ab2cbe262" class="toggle"><li><details open=""><summary>2.2.8 텐서의 실제 사례 </summary><ul id="acd02abf-ebaf-4abc-ad6e-a2ca0da52a76" class="bulleted-list"><li style="list-style-type:disc"><code>벡터 데이터</code><ul id="9278b998-7aa7-4670-be99-513f6f6bf2fb" class="bulleted-list"><li style="list-style-type:circle">(samples, features) </li></ul><ul id="3231fe02-2a5e-4db6-b059-6e7a7df281b2" class="bulleted-list"><li style="list-style-type:circle">2D 텐서 </li></ul></li></ul><ul id="4d818262-8bfe-46b4-ba7b-3ec7ebe61fdb" class="bulleted-list"><li style="list-style-type:disc"><code>시계열 데이터/ 시퀀스(sequence) 데이터</code><ul id="a598bc39-112b-4292-abc4-d80a77d11e1c" class="bulleted-list"><li style="list-style-type:circle"> (samples, timesteps, features) </li></ul><ul id="778fb9c5-a477-4f4c-9ce7-c74e7798bde5" class="bulleted-list"><li style="list-style-type:circle"> 3D 텐서 </li></ul></li></ul><ul id="d0409a92-7802-4061-b336-8e5afbcb3a4b" class="bulleted-list"><li style="list-style-type:disc"><code>이미지</code><ul id="b13f97d1-051c-48dd-9dff-2c2426f0fe65" class="bulleted-list"><li style="list-style-type:circle">(samples, height, width, channels) </li></ul><ul id="057d8475-5927-40e0-a1ec-3c95d30073bd" class="bulleted-list"><li style="list-style-type:circle">(samples, channels, height, width) </li></ul><ul id="898bae06-83c5-4d28-a287-1d9a9dc81dde" class="bulleted-list"><li style="list-style-type:circle">4D 텐서 </li></ul></li></ul><ul id="4fb6fa8f-f01f-4611-a38c-9b4054832734" class="bulleted-list"><li style="list-style-type:disc"><code>동영상</code><ul id="27d2c7e6-a505-446b-a1ef-ac2fb94b14b6" class="bulleted-list"><li style="list-style-type:circle">(samples, frames, height, width, channels)</li></ul><ul id="c3aba851-3a29-4f02-bccb-030ab640c60a" class="bulleted-list"><li style="list-style-type:circle">(samples/frames, channels, height, width) </li></ul><ul id="0753f26e-e296-4cdb-b97f-fefbab2fcc76" class="bulleted-list"><li style="list-style-type:circle">5D 텐서</li></ul></li></ul></details></li></ul><ul id="148f98da-28d6-401e-aeb9-650417c7de8f" class="toggle"><li><details open=""><summary>2.2.9 벡터 데이터 </summary><ul id="6ef1c4ee-0dd7-44a2-959d-87ebf7cd1c7f" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-orange">(samples, features) , 2D 텐서 </mark></li></ul><ul id="9363d09c-5e63-48e3-a0e4-84c844b3c4f9" class="bulleted-list"><li style="list-style-type:disc">하나의 데이터 포인트가 벡터로 인코딩 </li></ul><ul id="24e6c9d6-8e47-41bd-ac84-ec323c240a05" class="bulleted-list"><li style="list-style-type:disc">배치 데이터는 2D 텐서로 인코딩됨 </li></ul><ul id="f94a6726-2574-48f4-8cd0-7ad8b989553c" class="bulleted-list"><li style="list-style-type:disc">첫 번째 축은 <code>샘플 축</code>, 두 번째 축은 <code>특성 축 (feature axis)</code></li></ul><ul id="f1538a05-7cb3-46cc-b930-5ab782acd269" class="toggle"><li><details open=""><summary>ex1. 사람의 나이, 우편 번호, 소득으로 구성된 인구 통계 데이터 </summary><ul id="e7ad48b0-0957-4175-abb0-d4b3ef589373" class="bulleted-list"><li style="list-style-type:disc">각 사람은 3개의 값을 가진 벡터 </li></ul><ul id="850ad925-23d7-40a2-a66d-9896a9d4b895" class="bulleted-list"><li style="list-style-type:disc">10만 명이 포함된 전체 데이터셋은 (100,000, 3 ) 크기의 텐서 </li></ul></details></li></ul><ul id="e72cfa9a-3bcf-4cfa-8df1-2826959d1b4c" class="toggle"><li><details open=""><summary>ex2. (공통 단어 2만 개로 만든 사전에서)각 단어가 등장한 횟수로 표현된 텍스트 문서 데이터셋</summary><ul id="fa375857-8f9a-448d-94cf-d366ef19ec8d" class="bulleted-list"><li style="list-style-type:disc">각 문서는 2만 개의 원소(사전에 있는 단어마다 하나의 원소에 대응합니다)를 가진 벡터</li></ul><ul id="68f579fa-0315-4d8d-b758-5190aa7fe007" class="bulleted-list"><li style="list-style-type:disc">  500개의 문서로 이루어진 전체 데이터셋 : (500, 20,000) 크기의 텐서 </li></ul></details></li></ul></details></li></ul><ul id="028e1072-c7aa-46a4-9c93-a64daf12c5e7" class="toggle"><li><details open=""><summary>2.2.10 시계열 데이터 또는 시퀀스 데이터 </summary><ul id="ea500a5d-0a36-4975-89c3-dfbea058cc11" class="bulleted-list"><li style="list-style-type:disc"> <mark class="highlight-orange">(samples, timesteps, features) , 3D 텐서 </mark></li></ul><ul id="463e0815-b023-4a02-9e7a-9bce305debb1" class="bulleted-list"><li style="list-style-type:disc">시간(연속된 순서)가 중요할 때, 시간 축 포함하여 3D 텐서로 저장됨 </li></ul><ul id="385a3c03-bca2-4dea-9d0d-8b7206101ca3" class="bulleted-list"><li style="list-style-type:disc">각 샘플은 벡터(2D 텐서)의 시퀀스로 인코딩 → 배치 데이터 3D 텐서로 인코딩 </li></ul><ul id="b8064fa1-f674-4118-ab49-8e6971d9d577" class="toggle"><li><details open=""><summary>주식 가격 데이터셋</summary><ul id="686156bf-621d-4fd4-a9fb-8fe5dae990c5" class="bulleted-list"><li style="list-style-type:disc">1분마다 현재 주식 가격 </li></ul><ul id="49b81a15-d283-4768-ab66-cc4ff16f77a6" class="bulleted-list"><li style="list-style-type:disc">지난 1분 동안 최고 가격, 최소 가격을 저장 </li></ul><ul id="b8a84060-eca0-4a8d-af66-11276f418a9f" class="bulleted-list"><li style="list-style-type:disc">1분 마다 데이터 3D 벡터로 인코딩 </li></ul><ul id="086773ac-46f6-4ea9-ae1c-9724d3aed7f5" class="bulleted-list"><li style="list-style-type:disc">하루 동안(390분)의 거래 (390,3) 크기의 2D 텐서로 인코딩</li></ul><ul id="7902cc37-537e-43ff-a350-3d39ce9b4372" class="bulleted-list"><li style="list-style-type:disc">250일치 데이터: (250,390,3) 크기의 3D 텐서 </li></ul><ul id="11a9f5e9-9341-48fb-9e4b-d861851dc09c" class="bulleted-list"><li style="list-style-type:disc">1일치 데이터가 하나의 샘플  </li></ul></details></li></ul><ul id="390629e4-b0d5-48ac-a707-a2724539b4ec" class="toggle"><li><details open=""><summary>트윗 데이터셋 </summary><ul id="7ba14558-68df-46c1-be94-5dc0e87e9098" class="bulleted-list"><li style="list-style-type:disc">각 트윗은 128개의 알파벳으로 구성된 280개의 문자 시퀀스 </li></ul><ul id="74f79522-0456-4385-a830-8c313a9dc21e" class="bulleted-list"><li style="list-style-type:disc">각 문자가 128개의 크기인 이진 벡터로 인코딩 → 해당 문자만 1, 나머지 0 </li></ul><ul id="17638cd8-28dc-4b01-a103-79cdd33bcb1c" class="bulleted-list"><li style="list-style-type:disc">각 트윗은 (280,128) 크기의 2D 텐서로 인코딩 </li></ul><ul id="b8a0820f-4ba1-4cb6-9a3a-6983c6e6cee0" class="bulleted-list"><li style="list-style-type:disc">100만 개의 트윗으로 구성된 데이터셋 (100,000, 280, 128) 크기의 텐서에 저장  </li></ul></details></li></ul></details></li></ul><ul id="c25d1a46-6b82-4b25-afe0-0d09c4eca516" class="toggle"><li><details open=""><summary>2.2.11 이미지 데이터 </summary><ul id="66e66124-22f5-4cae-8b30-a5ddbbf18d78" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-orange">(samples, height, width, channels) /(samples, channels, height, width) /4D 텐서</mark></li></ul><ul id="20986781-56ea-4fc9-94ee-93a564eafa09" class="bulleted-list"><li style="list-style-type:disc">흑백 이미지: MNIST - 하나의 컬러 채널 - 2D 텐서<ul id="8ee6588f-7ee8-46d3-81c8-ff0a80f1fc96" class="bulleted-list"><li style="list-style-type:circle">컬러 채널의 차원 크기 : 1 </li></ul><ul id="c7e433c8-7b54-4a20-97d2-859a8cf3453f" class="bulleted-list"><li style="list-style-type:circle">256 x 256 크기의 흑백 이미지에 대한 128개의 배치 : <code>(128, 256, 256,1)</code></li></ul></li></ul><ul id="f66bdc35-371f-4bde-8bb1-98d6457f6365" class="bulleted-list"><li style="list-style-type:disc">컬러이미지 : 높이, 너비, 컬러 채널의 3차원 - 3D 텐서 <ul id="96812b9f-074f-4724-a580-dc5a8edb1f87" class="bulleted-list"><li style="list-style-type:circle">256 x 256 크기의 컬러 이미지(3) 에 대한 128개의 배치 :<code>(128, 256, 256, 3)</code></li></ul></li></ul><ul id="aac6c248-39d6-4bb4-ac9c-9a9160dc57d9" class="bulleted-list"><li style="list-style-type:disc">이미지 저장 방식<ul id="a073b936-8aac-4598-9b11-3fc4d8b6b4c4" class="bulleted-list"><li style="list-style-type:circle">채널 마지막 (channel-last) 방식<ul id="b569657b-d64d-4a30-8337-24815e08ba91" class="bulleted-list"><li style="list-style-type:square">Tensorflow: <mark class="highlight-orange">(samples, height, width, channels = color_depth)</mark></li></ul></li></ul><ul id="7f1f1a07-f620-4fa0-ad7f-42ea0ec32578" class="bulleted-list"><li style="list-style-type:circle">채널 우선 (channel-first) 방식<ul id="f4ef2808-a8a6-4546-8325-b5e29cc5f7c7" class="bulleted-list"><li style="list-style-type:square">채널의 깊이를 배치 축 바로 뒤에 놓음  </li></ul><ul id="176aa896-70ce-42c0-a94d-6ecbb7997630" class="bulleted-list"><li style="list-style-type:square">Theano :  <mark class="highlight-orange">(samples, color_depth, height, width)</mark></li></ul><ul id="c800a981-5ecb-4821-b0b4-cd6df0c0b2f2" class="bulleted-list"><li style="list-style-type:square"><code>흑백: (128,1,256,256)</code></li></ul><ul id="807478cc-35f0-4eb5-8db3-2061ae67f599" class="bulleted-list"><li style="list-style-type:square"><code>컬러: (128,3,256,256)</code></li></ul></li></ul></li></ul></details></li></ul><ul id="4d9a6a9e-5fe4-4984-b0db-7ecfef50a6a4" class="toggle"><li><details open=""><summary>2.2.12 비디오 데이터 </summary><ul id="c3cd2a6a-f2f9-4e1e-96b3-9796bd70816b" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-orange">(samples, frames, height, width, channels)/(samples/frames, channels, height, width)/5D 텐서</mark></li></ul><ul id="3df93fc6-4192-453a-a01c-7971106d2ae7" class="toggle"><li><details open=""><summary>하나의 비디오 </summary><ul id="c08b700d-0d42-4c58-ac76-7022d7ca7a01" class="bulleted-list"><li style="list-style-type:disc">비디오: <code>(samples, frames, height, width, color_depths)</code>의 5D 텐서 </li></ul><ul id="dbbd19a7-e3a0-41d7-a015-dca4fd5bbf09" class="bulleted-list"><li style="list-style-type:disc">연속된 프레임: <code>(frames, height, width, color_depth)</code>의 4D 텐서 </li></ul><ul id="82661682-2da5-495e-9806-27b44d94b5e7" class="bulleted-list"><li style="list-style-type:disc">각 프레임 = 하나의 컬러 이미지  - <code>(height, width, color_depth)</code>의 3D 텐서</li></ul><ul id="725c4abd-b9c4-4d27-bead-5d6953819f02" class="toggle"><li><details open=""><summary>ex. 60 초짜리 144 x 256 유튜브 비디오 클립 / 초당 4프레임으로 샘플링 / 240프레임 </summary><ul id="e39f4bd8-7f31-4f6f-bad6-a98346a170be" class="bulleted-list"><li style="list-style-type:disc">이런 비디오 클립 4개를 가진 배치 : (4,240,144,256,3) : 106,168,320개의 값 </li></ul><ul id="4ccf0bae-b1e7-4d13-85e4-f8cd91973b50" class="bulleted-list"><li style="list-style-type:disc">dtype: float 32 로 했다면 32 비트로 저장됨: 405MB</li></ul><ul id="fd3068f1-d36f-4456-b9ba-a2319a8419ea" class="bulleted-list"><li style="list-style-type:disc">실생활의 비디오 float 32크기로 저장 X, 훨씬 용량 적고, 압축됨 (MPEG)</li></ul></details></li></ul></details></li></ul></details></li></ul></details></li></ul><ul id="4e748d4c-2348-448e-9fc4-4ac70ffc6d73" class="toggle"><li><details open=""><summary>2.3 신경망의 톱니바퀴: 텐서 연산 </summary><pre id="88832569-c471-4a2f-86a1-cfb5ddc719f4" class="code code-wrap"><code># Dense 층을 쌓아 신경망 만듦 
keras.layers.Dense(512, activation = &#x27;relu&#x27;) 

# 2D 텐서를 입력으로 받고 
# 입력 텐서의 새로운 표현인 
# 또 다른 2D 텐서를 반환하는 함수
# (w: 2D 텐서 , b: 벡터)  

output = relu(dot(W, input) + b)
	# 입력 텐서와 텐서 w 사이의 점곱(dot)
	# 점곱의 결과인 2D 텐서와 벡터 b사이의 덧셈(+) 
	# 마지막으로 relu(렐루) 연산 
	# relu(x) = max(x,0) </code></pre><ul id="c7450f3e-a328-43bf-8d4e-f6ec591b63a5" class="toggle"><li><details open=""><summary>2.3.1 원소별 연산 </summary><ul id="78f253bc-f93a-4aed-b192-a0a6c457e76d" class="bulleted-list"><li style="list-style-type:disc">원소별 연산(element-wise operation)<ul id="a4182998-6522-4bb2-92b8-629944cca558" class="bulleted-list"><li style="list-style-type:circle">relu 함수 &amp; 덧셈 </li></ul><ul id="e8474990-d80a-435d-9ce1-a60878857873" class="bulleted-list"><li style="list-style-type:circle">텐서에 있는 각 원소에 독립적으로 적용됨 </li></ul><pre id="21037867-2e31-485a-b369-825dad1f424d" class="code code-wrap"><code>#------------------------
# 함수를 통한 연산 
#------------------------
# Relu 함수  
def naive_relu(x) :
	assert len(x.shape) == 2 # x는 2D 넘파이 배열 

	x = x.copy() # 입력 텐서 자체를 바꾸지 않도록 복사 
	for i in range(x.shape[0]):
		for j in range(x.shape([1]):
			x[i.j] = max(x[i,j], 0)
	return x 

# Add(덧셈) 함수 
def naive_add(x,y):
	asset len(x.shape) == 2 # x는 2D 넘파이 배열 
	asset x.shape == y.shape 

	x = x.copy() # 입력 텐서 자체를 바꾸지 않도록 복사
	for i in range(x.shape[0]):
		for j in range(x.shape[1]):
			x[i,j] + = y[i,j]
	return x 

# 함수 매개변수 수장 가능한 (mutable) 데이터 타입인 경우  
	# 참조에 의한 호출(call by reference) 처럼
	# 배열 원본을 변경시키지 않기 위해 복사 필요  

#------------------------
# 내장 함수를 통한 연산 
#------------------------
import numpy as np 
z = x + y # 원소별 덧셈 
z = np.maximum(z, 0.) # 원소별 렐루 함수 </code></pre></li></ul></details></li></ul><ul id="9ab404f2-4db4-4792-9f1e-cbc9b4dacaf7" class="toggle"><li><details open=""><summary>2.3.2 브로드캐스팅 </summary><ul id="0a507157-8b99-42fb-8488-0b9e8db708d4" class="bulleted-list"><li style="list-style-type:disc">크기가 다른 두 텐서가 더해질 때<ul id="8a68b331-157e-4da4-9d6f-66c5fb2d73b4" class="bulleted-list"><li style="list-style-type:circle">작은 텐서가 큰 텐서에 크기에 맞게 <code>브로드캐스팅(broadcasting)됨</code></li></ul><ul id="e0c79f87-c915-42eb-8a89-dc036abfcdbe" class="bulleted-list"><li style="list-style-type:circle">큰 텐서의 ndim 에 맞춰 작은 테서에 축이 추가됨 </li></ul><ul id="954ecb25-3c76-4087-be23-5e075631a65a" class="bulleted-list"><li style="list-style-type:circle">작은 텐서가 새 축을 따라 큰 텐서의 크기에 맞도록 반복됨 </li></ul><pre id="2dc471e5-a786-4140-a5eb-fb8a4939ff3b" class="code code-wrap"><code># X shape:  (32,10)
# y shape: (10,)
# X + y ? -&gt; Broadcasting 

# Broadcasting 과정 
	# y에 비어 있는 첫 번째 축을 추가 y: (1,10)
	# y를 이 축에 32번 반족 : 텐서 y: (32,10)
	# Y[i:, :] == y for i in range(0,32) 
	# X + y 

def naive_add_matrix_and_vector(x,y):
	assert len(x.shape) == 2 # x는 2D 넘파이 배열 
	assert len(y.shape) == 1 # y는 넘파이 벡터 
	assert x.shape[1] == y.shape[0]

	x = x.copy() # 입력 텐서 자체를 바꾸지 않도록 복사함 
	for i in range(x.shape[0]):
		for j in range(x.shape[1]):
			x[i,j] += y[j]
	return x 

# (a,b,,..n, n+1, ,,,m) 크기의 텐서 
# (n, n+1, ,,,m) 크기의 텐서 사이 브로드캐스팅으로 원소별 연산 적용 
# 브로드캐스팅은 a 부터 n-1까지 축에 자동으로 일어남 </code></pre><pre id="2c7cf935-351e-48b5-8806-38db88ba656a" class="code code-wrap"><code># 크기가 다른 두 텐서에 브로드캐스팅 
	# 원소별 maximum 연산 적용 

import numpy as np 
x = np.random.random((64,3,32,10)) # x 는 (64,3,32,10) 크기의 랜덤 텐서 
y = np.random.random((32,10)) # y는 (32,10) 크기의 랜덤 텐서 
z = np.maximum(x,y) # 출력 z 크기는 x 와 동일하게 (64,3,32,10) </code></pre></li></ul></details></li></ul><ul id="d00bf710-7d94-4202-991d-9050a10a1f2f" class="toggle"><li><details open=""><summary>2.3.3 텐서 점곱 </summary><ul id="beeb91ba-16ce-4700-86d4-64bf80470710" class="bulleted-list"><li style="list-style-type:disc">텐서 접곰(tensor product) <ul id="6ce55e08-58d9-4c73-ba18-d0862d53a96c" class="bulleted-list"><li style="list-style-type:circle">원소별 곱셈 X </li></ul><ul id="bd5dfe5e-e779-4425-a594-7c6d42bcdb45" class="bulleted-list"><li style="list-style-type:circle">점곱 연산(dot operation) - 입력 텐서의 원소들 결합 <pre id="92b5b278-a30f-4f54-b25d-aaed0cab78aa" class="code code-wrap"><code># 1. 벡터끼리의 점곱 연산 
	# 2개의 벡터 x와 y 의 점곱 
	# 두 벡터의 점곱: 스칼라가 됨 
	# 원소 개수가 같은 벡터끼리 점곱이 가능 
def naive_vector_dot(x,y): 
	assert len(x.shape) == 1 # x와 y는 넘파이 벡터 
	assert len(y.shape) == 1 # x와 y는 넘파이 벡터
	assert x.shape[0] == y.shape[0] 

	z = 0.
	for i in range(x.shape([0]):
		z += x[i] * y[i]
	return z </code></pre><pre id="fd96368d-16aa-486c-9873-be55096e833d" class="code code-wrap"><code># 2. 행렬과 벡터의 접곱 연산 
	# x: 행렬, y: 벡터 
	# y와 x 의 행 사이에 점곱 : 벡터를 반환 
import numpy as np 
def naive_matrix_vector_dot(x,y):
	assert len(x.shape) == 2 # x의 넘파이 행렬 
	assert len(y.shape) == 1 # y는 넘파이 벡터 
	assert x.shape[1] == y.shape[0] # x의 두 번째 차원 = y의 첫 번째 차원 

	z = np.zeros(x.shape[0]) # x의 행과 같은 크기의 0 이 채워진 벡터 
	for i in range(x.shape[0]):
		for j in range(x.shape[1]):
				z[i] += x[i,j] * y[j] 
	return z </code></pre><pre id="66460935-e23e-4926-a90c-215692c1f4c2" class="code code-wrap"><code># 3.행렬-벡터 점곱 &amp; 벡터-벡터 점곱 

def naive_matrix_vector_doc(x,y):
	z = np.zeros(x.shape[0])
	for i in range(x.shape[0]):
		z[i] = naive_vector_dot(x[i,:], y)
	return z

# 4. 단순 dot연산 구현 
def naive_matrix_dot(x,y):
	assert len(x.shape) == 2 # x,y 는 넘파이 행렬 
	assert len(y.shape) == 2 # x,y 는 넘파이 행렬 
	assert x.shape[1] == y.shape[0] # x는 2번째 차원이 y의 첫 번째 차원과 같아야 함 

	z = np.zeros((x.shape[0], y.shape[1])) # 0이 채워진 특정 크기의 벡터를 만듦
	for i in range(x.shape[0]): # x의 행을 반복합니다 
		for j in range(y.shape[1]): # y의 열을 반복합니다 
			row_x = x[i, :]
			column_y = y[:,j]
			z[i,j] = naive_vector_dot(row_x, column_y)
	return z  </code></pre></li></ul><ul id="e639fdd0-0916-4e7d-a42d-e6c2ea47d2e7" class="bulleted-list"><li style="list-style-type:circle">numpy, keras, theano, tensorflow 곱셈:  * 연산자 </li></ul><ul id="7b122bc2-6715-46a2-aa24-f7bdf6d38199" class="bulleted-list"><li style="list-style-type:circle">tensorflow dot 연산자 <pre id="4e8d0c52-8e78-4b0e-8b46-394994753c40" class="code code-wrap"><code># tensorflow dot 연산자 
tf.matmul(x,y) 

# python (v 3.5&gt; ) : 
x @ y </code></pre></li></ul><ul id="52f89757-f311-4dbf-8d5a-ee641c93bf0a" class="bulleted-list"><li style="list-style-type:circle">numpy, keras dot 연산자 <pre id="5cfa063f-a7bd-4da5-a54f-5952e2845912" class="code code-wrap"><code># Numpy 
import numpy as np 
Z = np.dot(x,y) 

# Keras 
from keras import backend as K 
K.dot(x,y) </code></pre></li></ul></li></ul></details></li></ul><ul id="0cd07e1a-e80d-4368-95d0-74f121f22a1b" class="toggle"><li><details open=""><summary>2.3.4 탠서 크기 변환 </summary><ul id="e7fc6f79-164b-4204-93fd-693d546c9baa" class="bulleted-list"><li style="list-style-type:disc">텐서 크기 변환(tensor reshaping)<ul id="9b1b6690-e30b-4b06-b145-1ccddd31e56d" class="bulleted-list"><li style="list-style-type:circle">텐서의 크기를 변환하는 것은 특정 크기에 맞게 열과 행을 재배열한다는 뜻</li></ul><ul id="8e53c9db-81d4-4c49-bce5-2cd2af4c66d8" class="bulleted-list"><li style="list-style-type:circle">크기가 변환된 텐서는 원래 텐서와 원소 개수는 동일  </li></ul><ul id="03738c1c-79c8-4db8-91ee-4a3ce5a85d58" class="bulleted-list"><li style="list-style-type:circle">자주 사용하는 크기 변환은 전차(transposition) <ul id="cbe6b42d-63a6-473b-8234-89146c4ff1da" class="bulleted-list"><li style="list-style-type:square">행과 열을 바꾸는 것 x[i, :] → x[:, i]가 됨 </li></ul></li></ul><ul id="9d03f784-07cb-4797-b967-a215a0c507d5" class="bulleted-list"><li style="list-style-type:circle"><code>train_images = train_images.reshape((60000,28 * 28))</code></li></ul><pre id="be62f5ff-aeed-4690-970e-0dc44611b6e3" class="code code-wrap"><code>x = np.array([[0., 1.],
							[2., 3.],
							[4., 5.]])

print(x.shape) # [3,2]

x = x.reshape((6,1))
x # 하면 6개 행인 array 생성됨 

x = x.reshape((2,3))
x </code></pre><pre id="beaec3b9-6f21-40f2-b977-a0fad227c315" class="code code-wrap"><code>x = np.zeros((300,20)) # 모두 0으로 채워진 (300,20) 크기의 행렬을 만듦 
x = np.transpose(x)
print(x.shape) # (20,300) </code></pre></li></ul></details></li></ul><ul id="cf7c4a8b-b623-46b7-b4ea-0597bff98f65" class="toggle"><li><details open=""><summary>2.3.5 텐서 연산의 기하학적 해석</summary></details></li></ul><ul id="d628792a-49fc-4dac-9068-4dfc4b6eb32e" class="toggle"><li><details open=""><summary>2.3.6 딥러닝의 기하학적 해석 </summary></details></li></ul></details></li></ul><ul id="9bea2e3d-3d43-4934-a866-50ff52d803c3" class="toggle"><li><details open=""><summary>2.4 신경망의 엔진: 그래디언트 기반 최적화 </summary><p id="6fe190ae-20c7-4d0e-ab68-cddbe726a5dc" class=""><code>output = relu(dot(W, input) + b) </code><div class="indented"><ul id="125100e7-0322-49ee-809b-490c1066c547" class="bulleted-list"><li style="list-style-type:disc">W와 b는 층의 속성처럼 볼 수 있음 </li></ul><ul id="d808e13f-c0d5-4bcf-b2a7-7b92db462eb3" class="bulleted-list"><li style="list-style-type:disc">가중치(weight) 또는 훈련되는 파라미터(trainable parameter)라고 부름</li></ul><ul id="82cda338-b851-4ef9-8550-d34e3c24cc05" class="bulleted-list"><li style="list-style-type:disc">가중치에는 훈련 데이터를 신경망에 노출시켜서 학습된 정보가 담겨 있음  </li></ul><ul id="3f74bc31-5147-4d3e-bd4f-01c48bf44879" class="bulleted-list"><li style="list-style-type:disc">초기에는 가중치 행렬이 난수로 채워져 있음(무작위 초기화(random initialization) 단계라고 부름</li></ul><ul id="05bde973-a659-4333-9d01-5d552200bf6f" class="bulleted-list"><li style="list-style-type:disc">피드백 신호에 기초하여 가중치가 점진적으로 조정됨 → 훈련 (training) </li></ul><ul id="a28a4f1e-2383-462e-8d8b-ae8e0325cee5" class="bulleted-list"><li style="list-style-type:disc">훈련 반복 루프(training loop) 가 발생 </li></ul><ul id="1c8303c0-6229-4c43-afdf-2e73dd404091" class="bulleted-list"><li style="list-style-type:disc">신경망에서 사용된 모든 연산은 미분 가능(differentiable) </li></ul><ul id="9ba8d5e4-691b-4e16-a9da-18c24e10e8cf" class="bulleted-list"><li style="list-style-type:disc">네트워크 가중치에 대한 손실을 그래디언트(gradient)를 계산하는 것이 훨씬 더 좋은 방법  </li></ul><ul id="73a233d2-5adb-4e0d-a9b8-2d60b89c97fa" class="toggle"><li><details open=""><summary>2.4.1 변화율이란? </summary><ul id="f3b2580c-633c-4e08-a74a-d327a299c71c" class="bulleted-list"><li style="list-style-type:disc">f(x + epsilon_x)  = y + epsilon_y </li></ul></details></li></ul><ul id="cca93d31-df49-459f-b989-b56a1105513f" class="toggle"><li><details open=""><summary>2.4.2 텐서 연산의 변화율 : 그래디언트</summary><ul id="b9a1b077-e69a-422e-872c-6d309145670a" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-orange">그래디언트 : 텐서 연산의 변화율 </mark></li></ul><ul id="ba8acc90-2d9a-45cc-b5b0-36980db1a9fc" class="bulleted-list"><li style="list-style-type:disc">입력 벡터 : x , 행렬: W, 타깃: y, 손실 함수: loss <ul id="0cebd709-287b-4b60-a9de-8247bfd7d0a5" class="bulleted-list"><li style="list-style-type:circle">W를 사용하여 타깃의 에측 y_pred 를 계산하고, y_pred와 y사이의 오차를 계산 </li></ul><ul id="13083133-aba1-4810-bf37-49ec326bbf55" class="bulleted-list"><li style="list-style-type:circle"><code>y_pred = dot(W,x) </code></li></ul><ul id="3e35a44a-c828-45e0-928c-bb6a9ed299ba" class="bulleted-list"><li style="list-style-type:circle"><code>loss_value = loss(y_pred, y)</code></li></ul></li></ul></details></li></ul><ul id="7daa0977-e29f-47d6-ace3-b403de78b9ab" class="toggle"><li><details open=""><summary>2.4.3 확률적 경사 하강법 </summary><ul id="359ec19a-fcb3-488f-aa01-a7bc815026a0" class="bulleted-list"><li style="list-style-type:disc">미니 배치 확률적 경사 하강법(mini-batch stochastic gradient descent, 미니 배치 SGD)</li></ul><ul id="6c52d353-47ea-49a2-a7ae-6c66d90169cf" class="bulleted-list"><li style="list-style-type:disc">확률적(stochastic) → 각 배치 데이터가 무작위로 선택된다는 의미 </li></ul><ul id="91b05ceb-c9b9-4681-a93e-d68c60163fcc" class="bulleted-list"><li style="list-style-type:disc">무작위(random) 하다는 것의 과학적 표현 <ul id="02498db8-cf29-44ea-a8e1-f85252cbfeeb" class="bulleted-list"><li style="list-style-type:circle">반복마다 하나의 샘플과 하나의 타깃을 뽑는 것 , 배치 SGD</li></ul></li></ul><ul id="572f116c-6b2d-4d48-a96e-37ac9401c2bc" class="bulleted-list"><li style="list-style-type:disc"><code>SGD의 변종 /최적화 방법(optimization method)/ 옵티마이저 </code><ul id="098e9295-de8f-441a-8efe-21be0a787a57" class="bulleted-list"><li style="list-style-type:circle"><code>SGD, Adagrad, RMSProp</code></li></ul><ul id="d098291e-1d3a-45d3-a8dc-d3df5ea20d11" class="bulleted-list"><li style="list-style-type:circle">여러 변동즐에서 사용하는 모멘텀(momentum) 개념 중요 </li></ul><ul id="ec50b6f8-829e-4d1a-bc53-3d51ce78016a" class="bulleted-list"><li style="list-style-type:circle">모멘텀은 수렴 속도와 지역 최솟값을 모두 해결함 </li></ul></li></ul><p id="74f56b71-bd48-4ab3-9207-3d6840e02002" class="">
</p></details></li></ul><ul id="34c6fa50-e625-4368-9c72-34372ee294ae" class="toggle"><li><details open=""><summary>2.4.4. 변화율 연결: 역전파 알고리즘 </summary><ul id="27c636e4-1cb1-4c73-8940-6b9a3cdf56dd" class="bulleted-list"><li style="list-style-type:disc">텐서 연산 a,b,c / 가중치 행렬 W1, W2, W3 로 구성된 네트워크 f </li></ul><ul id="156bd7be-88ef-4a06-91f5-80954c024baf" class="bulleted-list"><li style="list-style-type:disc">f(W1,W2,W3) = a(W1, b(W2, c(W3))<ul id="e2b2b1bb-dd83-491b-b9e1-3df9102bb7e0" class="bulleted-list"><li style="list-style-type:circle">연쇄 법칙(chain rule) 을 신경망의 그래디언트 계산에 적용 </li></ul><ul id="e6999a18-132a-4835-af6c-6e2c0bedba41" class="bulleted-list"><li style="list-style-type:circle">역전파(Backpropagation) 알고리즘 (후진 모드 자동 미분)) 가능 </li></ul></li></ul></details></li></ul></div></p></details></li></ul><ul id="cc249ecf-b8af-4248-b048-5552459ccbb8" class="toggle"><li><details open=""><summary>2.5 첫 번째 예제 다시 살펴보기 </summary><pre id="2a9bd967-19f9-4c81-a91b-e3d0a1608bc4" class="code code-wrap"><code># 입력 데이터 
(train_iamges, train_labels), (test_images, test_labels) = mnist.load_data()

train_images = train_images.reshape((60000, 28 * 28)) # (60,000, 784) 크기 넘파이 배열 
train_images = train_images.astype(&#x27;float32&#x27;) / 255  # 데이터 타입 : float32 

test_images = test_images.reshape((10000, 28 * 28)) # (10,000, 784) 크기 넘파이 배열 
test_images = ttest_images.astype(&#x27;float32&#x27;) / 255 # 데이터 타입 : float32 

# 신경망 모형 
network = models.Sequential() 
network.add(layers.Dense(512, activation = &#x27;relu&#x27;, input_shape = (28,28, ))
network.add(layers.Dense(10, activation = &#x27;softmax&#x27;)) 

# 컴파일
network.compile(optimizer = &#x27;rmsprop&#x27;,
								loss = &#x27;categorical_crossentropy&#x27;,
								metrics=  [&#x27;accuracy&#x27;])

# 훈련 방법
	# 네트워크가 128개 샘플씩 미니 배치로 훈련 데이터를 다섯 번 반복 
	# 각 반복을 에포크(epoch)  
network.fit(train_iamges, train_labels, epoch = 5, batch_size = 128) </code></pre></details></li></ul><ul id="473d086c-7394-4a73-a076-e93ee8978e4a" class="toggle"><li><details open=""><summary>2.6 요약 </summary><ul id="f5a04ec6-a2cc-42b5-ac10-52c18f347c79" class="bulleted-list"><li style="list-style-type:disc">학습(learning)은 훈련 데이터 샘플과 타깃이 주어졌을 때 손실 함수를 최소화하는 모델 파라미터 조합을 찾는 것 </li></ul><ul id="1479b886-85b6-462c-9572-54c915dd1cee" class="bulleted-list"><li style="list-style-type:disc">손실과 옵티마이저! <ul id="ba1932ec-9df1-4038-9667-d614255c3da0" class="bulleted-list"><li style="list-style-type:circle">손실 : 훈련하는 동안 최소화해야 할 양, 해결하려는 문제의 성공을 측정하는데 사용함 </li></ul><ul id="62c07c2f-7c8c-4724-902b-91e2e68f6199" class="bulleted-list"><li style="list-style-type:circle">옵티마이저: 손실에 대한 그래디언트가 파라미터를 업데이트하는 정확한 방식을 정의함 <ul id="cfcfe5bd-bf96-48b4-b3f7-e211c681d9e1" class="bulleted-list"><li style="list-style-type:square">RMSProp, 모멘텀을 사용한 SGD 등 </li></ul></li></ul></li></ul></details></li></ul></details></li></ul><p id="0ff0ec0a-53f9-4223-8c53-836fb4426713" class="">
</p></div></article></body></html>